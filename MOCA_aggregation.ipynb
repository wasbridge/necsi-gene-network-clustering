{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "2019-05-02 09:20:56.190023\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as ml\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import statistics\n",
    "import csv\n",
    "\n",
    "def parseStage(stage):\n",
    "    return float(stage[1:])\n",
    "\n",
    "print('Here')\n",
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "2019-05-01 16:23:25.270539\n"
     ]
    }
   ],
   "source": [
    "rawGeneToGoidData = pd.read_csv('MOCA-data/endoderm_counts/associations/mgi_annotations.mapped.csv')\n",
    "rawGoidToNameData = pd.read_csv('MOCA-data/endoderm_counts/associations/go_terms_slim_mouse.csv')\n",
    "rawSparseMatrix = pd.read_csv('MOCA-data/endoderm_counts/endoderm_counts.dat', delimiter=' ')\n",
    "rawMetaData = pd.read_csv('MOCA-data/endoderm_counts/endoderm_meta.csv')\n",
    "rawGeneList = pd.read_csv('MOCA-data/endoderm_counts/genesList.csv')\n",
    "\n",
    "print('Here')\n",
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "2019-05-01 16:23:25.278828\n"
     ]
    }
   ],
   "source": [
    "#properly indexed genes\n",
    "genes = [element.upper() for element in list(rawGeneList.Symbol)]\n",
    "\n",
    "print('Here')\n",
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "2019-05-01 16:23:25.529920\n"
     ]
    }
   ],
   "source": [
    "#map of gene name to unique set of GO_ID\n",
    "geneToGoidMap = {}\n",
    "\n",
    "for val in list(zip(rawGeneToGoidData.DB_object_symbol, rawGeneToGoidData.GO_ID)):\n",
    "    gene = val[0].upper()\n",
    "    if not gene in geneToGoidMap:\n",
    "        geneToGoidMap[gene] = set()\n",
    "        \n",
    "    geneToGoidMap[gene].add(val[1])\n",
    "\n",
    "print('Here')\n",
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "2019-05-02 09:15:27.161973\n"
     ]
    }
   ],
   "source": [
    "#map of GO_ID to variable name\n",
    "goidToVariableNameMap = {}\n",
    "goidToAspectMap = {}\n",
    "\n",
    "for val in list(zip(rawGoidToNameData.GO_ID, rawGoidToNameData.Name, rawGoidToNameData.Aspect)):\n",
    "    assert not(val[0] in goidToVariableNameMap), \"Duplicate GOID \" + val[0]\n",
    "    goidToVariableNameMap[val[0]] = val[1]\n",
    "    goidToAspectMap[val[0]] = val[2]\n",
    "        \n",
    "print('Here')\n",
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "2019-05-01 17:22:58.683876\n",
      "Processing Sample: 0\n",
      "Processing Sample: 1000000\n",
      "Processing Sample: 2000000\n",
      "Processing Sample: 3000000\n",
      "Processing Sample: 4000000\n",
      "Processing Sample: 5000000\n",
      "Processing Sample: 6000000\n",
      "Processing Sample: 7000000\n",
      "Processing Sample: 8000000\n",
      "Processing Sample: 9000000\n",
      "Processing Sample: 10000000\n",
      "Processing Sample: 11000000\n",
      "Processing Sample: 12000000\n",
      "Processing Sample: 13000000\n",
      "Processing Sample: 14000000\n",
      "Processing Sample: 15000000\n",
      "Processing Sample: 16000000\n",
      "Processing Sample: 17000000\n",
      "Genes which arent in goslim 4550\n",
      "Genes which are in goslim 14746\n",
      "2019-05-01 17:36:02.456952\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting\")\n",
    "print(str(datetime.datetime.now()))\n",
    "\n",
    "class RowResult:\n",
    "    empty = True\n",
    "    gene = ''\n",
    "    missing = False\n",
    "    found = False\n",
    "    pickledValuesByGoidByTime = None\n",
    "\n",
    "def processRow(row):\n",
    "    ret = RowResult()\n",
    "    \n",
    "    if row[0] % 1000000 == 0:\n",
    "        print('Processing Sample: ' + str(row[0]))\n",
    "    \n",
    "    if row[1] - 1 >= len(genes):\n",
    "        print(\"Gene Index Error: \" + str(row))\n",
    "        return ret\n",
    "        \n",
    "    gene = genes[row[1]- 1]\n",
    "    ret.gene = gene\n",
    "    ret.empty = False\n",
    "    \n",
    "    if not gene in geneToGoidMap:\n",
    "        ret.missing = True\n",
    "        return ret\n",
    "    else:\n",
    "        ret.found = True\n",
    "        \n",
    "    if row[2] - 1 >= len(rawMetaData.index):\n",
    "        print('Meta Index Error: ' + str(row))\n",
    "        return ret;\n",
    "    \n",
    "    stage = rawMetaData.iloc[row[2] - 1].stage\n",
    "    if stage == 'mixed_gastrulation':\n",
    "        return ret\n",
    "    \n",
    "    time = parseStage(stage)\n",
    "        \n",
    "    goids = geneToGoidMap[gene]\n",
    "    valuesByGoidByTime = {}\n",
    "    for goid in goids:\n",
    "        if not goid in valuesByGoidByTime:\n",
    "            valuesByGoidByTime[goid] = {}\n",
    "            \n",
    "        if not time in valuesByGoidByTime[goid]:\n",
    "            valuesByGoidByTime[goid][time] = []\n",
    "        \n",
    "        valuesByGoidByTime[goid][time].append(row[3])\n",
    "    \n",
    "    ret.pickledValuesByGoidByTime = pickle.dumps(valuesByGoidByTime)\n",
    "    return ret\n",
    "\n",
    "#map of goid to map of time to list of value\n",
    "valuesByGoidByTime = {}\n",
    "#these are the genes that don't fit our aggregation model (AKA not in goslim)\n",
    "missingGenes = set()\n",
    "#these are the genes that do fit our aggregation model\n",
    "foundGenes = set()\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    result = pool.imap(processRow, rawSparseMatrix.itertuples(name=None), chunksize=100000)\n",
    "    output = [x for x in result]\n",
    "    for ret in output:\n",
    "        if ret.empty:\n",
    "            continue;\n",
    "        \n",
    "        if ret.missing:\n",
    "            missingGenes.add(ret.gene)\n",
    "        elif ret.found:\n",
    "            foundGenes.add(ret.gene)\n",
    "            if ret.pickledValuesByGoidByTime: #mixed_gastrulation will be found, but null\n",
    "                for goid, retValuesByGoidByTime in pickle.loads(ret.pickledValuesByGoidByTime).items():\n",
    "                    if not goid in valuesByGoidByTime:\n",
    "                        valuesByGoidByTime[goid] = {}\n",
    "\n",
    "                    for time, values in retValuesByGoidByTime.items():\n",
    "                        if not time in valuesByGoidByTime[goid]:\n",
    "                            valuesByGoidByTime[goid][time] = []\n",
    "\n",
    "                        valuesByGoidByTime[goid][time].extend(values);\n",
    "                        \n",
    "print('Genes which arent in goslim ' + str(len(missingGenes)))\n",
    "print('Genes which are in goslim ' + str(len(foundGenes)))\n",
    "print(str(datetime.datetime.now()))\n",
    "print(len(valuesByGoidByTime.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mean\n",
      "2019-05-02 09:30:13.420902\n",
      "Done -- open out/aggregation_mean.csv\n",
      "2019-05-02 09:31:06.790248\n",
      "Starting median\n",
      "2019-05-02 09:31:06.790365\n",
      "Done -- open out/aggregation_median.csv\n",
      "2019-05-02 09:31:13.924520\n",
      "Starting stdev\n",
      "2019-05-02 09:31:13.924954\n",
      "Done -- open out/aggregation_stdev.csv\n",
      "2019-05-02 09:34:36.316301\n",
      "Starting variance\n",
      "2019-05-02 09:34:36.316333\n",
      "Done -- open out/aggregation_variance.csv\n",
      "2019-05-02 09:37:56.272871\n"
     ]
    }
   ],
   "source": [
    "stats = ['mean', 'stdev', 'variance'] #these are methods on the python3 statistics module that we want to run\n",
    "\n",
    "for stat in stats:\n",
    "    print(\"Starting \" + stat)\n",
    "    print(str(datetime.datetime.now()))\n",
    "    csvData = []\n",
    "    header = ['Aspect', 'Variable']\n",
    "    timeRange = np.linspace(6.5, 8.5, 9)\n",
    "\n",
    "    for time in timeRange:\n",
    "        header.append(str(time))\n",
    "\n",
    "    csvData.append(header)\n",
    "\n",
    "    for goid, valuesByTime in valuesByGoidByTime.items():\n",
    "        row = []\n",
    "        variableName = goidToVariableNameMap[goid]\n",
    "        aspect = goidToAspectMap[goid]\n",
    "\n",
    "        row.append(aspect)\n",
    "        row.append(variableName)\n",
    "\n",
    "        for time in timeRange:\n",
    "            method = getattr(statistics, stat)\n",
    "            values = valuesByTime[time]\n",
    "            row.append(method(values))\n",
    "\n",
    "        csvData.append(row)\n",
    "\n",
    "    with open('out/aggregation_' + stat + '.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in csvData:\n",
    "            filewriter.writerow(row)\n",
    "\n",
    "    print('Done -- open out/aggregation_' + stat + '.csv')\n",
    "    print(str(datetime.datetime.now()))\n",
    "    \n",
    "print('Done Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
